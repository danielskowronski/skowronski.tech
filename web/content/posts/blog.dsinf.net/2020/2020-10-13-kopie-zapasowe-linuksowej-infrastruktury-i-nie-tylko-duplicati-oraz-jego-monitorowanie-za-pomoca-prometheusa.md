---
title: Kopie zapasowe linuksowej infrastruktury i nie tylko â€“ Duplicati oraz jego monitorowanie za pomocÄ… Prometheusa
author: Daniel SkowroÅ„ski
type: post
date: 2020-10-13T19:20:40+00:00
summary: 'SzukajÄ…c systemu do tworzenia kopii zapasowej, ktÃ³ry bÄ™dzie dziaÅ‚aÅ‚ zarÃ³wno na boxach na labowym serwerze, jak i na stacjach roboczych z Linuksem, Windowsem i macOS kilka lat temu zatrzymaÅ‚em siÄ™ na rozwiÄ…zaniu UrBackup, ktÃ³re opisaÅ‚em tutaj. SkusiÅ‚a mnie gÅ‚Ã³wnie funkcjonalnoÅ›Ä‡ backupowania nie tylko plikÃ³w, lecz i obrazÃ³w dyskÃ³w twardych. OkazaÅ‚o siÄ™ jednak, Å¼e dziaÅ‚a ona gÅ‚Ã³wnie na Windowsie przez VSS (Volume Shadow Copy), a na Linuksach wymaga zewnÄ™trznych skryptÃ³w, ktÃ³re zrobiÄ… migawkÄ™ systemu plikÃ³w mniej, lub bardziej inteligentnie (np. za pomocÄ… datto). Przez seriÄ™ problemÃ³w z triggerowaniem zadaÅ„ z serwera (gÅ‚Ã³wnie na stacjach roboczych, ktÃ³re nie sÄ… online 24/7) i przechodzeniem agentÃ³w w stan nieoperacyjny postanowiÅ‚em szukaÄ‡ dalej. Tym sposobem doszedÅ‚em do Duplicati i monitorowaniu go za pomocÄ… Prometheusa. '
url: /2020/10/kopie-zapasowe-linuksowej-infrastruktury-i-nie-tylko-duplicati-oraz-jego-monitorowanie-za-pomoca-prometheusa/
featured_image: /wp-content/uploads/2020/10/logo-duplicati.png
tags:
  - backup
  - duplicati
  - linux
  - monitoring
  - prometheus

---
SzukajÄ…c systemu do tworzenia kopii zapasowej, ktÃ³ry bÄ™dzie dziaÅ‚aÅ‚ zarÃ³wno na boxach na labowym serwerze, jak i na stacjach roboczych z Linuksem, Windowsem i macOS kilka lat temu zatrzymaÅ‚em siÄ™ na rozwiÄ…zaniu UrBackup, ktÃ³re [opisaÅ‚em tutaj][1]. SkusiÅ‚a mnie gÅ‚Ã³wnie funkcjonalnoÅ›Ä‡ backupowania nie tylko plikÃ³w, lecz i obrazÃ³w dyskÃ³w twardych. OkazaÅ‚o siÄ™ jednak, Å¼e dziaÅ‚a ona gÅ‚Ã³wnie na Windowsie przez VSS (Volume Shadow Copy), a na Linuksach wymaga zewnÄ™trznych skryptÃ³w, ktÃ³re zrobiÄ… migawkÄ™ systemu plikÃ³w mniej, lub bardziej inteligentnie (np. za pomocÄ… datto). Przez seriÄ™ problemÃ³w z triggerowaniem zadaÅ„ z serwera (gÅ‚Ã³wnie na stacjach roboczych, ktÃ³re nie sÄ… online 24/7) i przechodzeniem agentÃ³w w stan nieoperacyjny postanowiÅ‚em szukaÄ‡ dalej. Tym sposobem doszedÅ‚em do Duplicati i monitorowaniu go za pomocÄ… Prometheusa. 

## Kilka sÅ‚Ã³w o Duplicati

Duplicati przyciÄ…ga uwagÄ™ architekturÄ… nieposiadajÄ…cÄ… serwera - klienci posiadajÄ… zestaw narzÄ™dzi do wykonania backupu oraz opcjonalny scheduler i webowy interfejs konfiguracyjny. Te dwa ostatnie sÄ… przeznaczone dla stacji roboczych i statycznych serwerÃ³w (czyli raczej nie bÄ™dÄ… to kontenery). Backup wysyÅ‚any jest do _storage providera_ - moÅ¼e nim byÄ‡ lokalny folder, serwer FTP, Amazon S3, Dropbox i caÅ‚a masa innych. 

Poza tym caÅ‚oÅ›Ä‡ jest zaprojektowana tak, aby moÅ¼na byÅ‚o backup odtworzyÄ‡ rÄ™cznie - uÅ¼ywane sÄ… standardowe narzÄ™dzia takie jak zip i tar. Do szyfrowania uÅ¼ywany jest AES256 lub PGP. PrzenoÅ›noÅ›Ä‡ miÄ™dzy platformami zapewnia .NET framework - oznacza to pewien narzut zwiÄ…zany z instalacjÄ… Å›rodowiska mono na Linuksach, ale zapewnia elastycznoÅ›Ä‡.

Instalacja na desktopie jest Å›miesznie Å‚atwa, a konfiguracja w web-ui polega na odpowiedzi na seriÄ™ pytaÅ„ w wizardzie. Jest to pozytywna odmiana po narzÄ™dziach w rodzaju Bacula. Moim zdaniem uÅ¼ytkownicy wspÃ³Å‚czesnego Linuksa zasÅ‚ugujÄ… na Å‚atwe w obsÅ‚udze narzÄ™dzia.

## Instalacja i podstawu uÅ¼ywania

Jak siÄ™ ma sprawa na linuksowych boxach, ktÃ³re nie powinny wystawiaÄ‡ interfejsu konfiguracyjnego? PodejÅ›Ä‡ jest kilka, ale ja opiszÄ™ wykorzystanie crona do triggerowania zadaÅ„ oraz Prometheusa do monitorowania ich postÄ™pu.

Pierwszym krokiem jest instalacja - strona https://www.duplicati.com/download zawiera paczki dla Windowsa (msi), deb i rpm dla LinuksÃ³w oraz zipa z samymi plikami wykonywalnymi .net. deb i rpm sÄ… bezarchitekturowe - majÄ… dependencje na Å›rodowisko mono i to, co znajduje siÄ™ w archiwum zip - binarki. Oznacza to, Å¼e bez problemu odpalÄ… siÄ™ na RaspberryPi uÅ¼ywajÄ…cym procesora ARM.

**duplicati-cli** to narzÄ™dzie do wykonywania zadaÅ„, nas oczywiÅ›cie na tym etapie najbardziej interesuje `backup`

duplicati-cli:
```
See duplicati.commandline.exe help topic for more information.
 General: example, changelog
 Commands: backup, find, restore, delete, compact, test, compare, purge, vacuum
 Repair: repair, affected, list-broken-files, purge-broken-files
 Debug: debug, logging, create-report, test-filters, system-info, send-mail
 Targets: rclone, ftp, msgroup, onedrivev2, sharepoint, googledrive, gcs, cloudfiles, mega, s3, ssh, jottacloud, webdav, hubic, tahoe, b2, aftp, azure, file, od4b, mssp, openstack, box, sia, dropbox
 Modules: aes, gpg, zip, 7z, console-password-input, mssql-options, hyperv-options, http-options, sendhttp, sendmail, runscript, sendxmpp, check-mono-ssl
 Formats: date, time, size, encryption, compression
 Advanced: mail, advanced, returncodes, filter, filter-groups, option
```

## Wrapper i dygresja o autoryzacji do storage backendÃ³w

JeÅ›li zamierzamy wykorzystaÄ‡ duplicati-cli w wiÄ™cej niÅ¼ jednym miejscu warto pokusiÄ‡ siÄ™ o napisanie drobnego wrappera. MÃ³j dostosowany jest do wysyÅ‚ania danych na dropboxa, wiÄ™c jednym z parametrÃ³w jest auth_id - token aplikacji. 

Warto w tym miejscu zrobiÄ‡ dygresjÄ™ - Duplicati ogarnia to, co jest najwiÄ™kszÄ… bolÄ…czkÄ… tego typu rozwiÄ…zaÅ„, ktÃ³re integrujÄ… siÄ™ z dostawcami powierzchni dyskowej jak OneDrive, czy Dropbox. TwÃ³rcy hostujÄ… serwer (rozwiÄ…zanie opensource, ktÃ³re moÅ¼na postawiÄ‡ samodzelnie jeÅ›li im nie ufamy) sÅ‚uÅ¼Ä…cy do pobierania tokenÃ³w od providerÃ³w. DostÄ™p do niego jest wbudowany w web-ui, moÅ¼na teÅ¼ osiÄ…gnÄ…Ä‡ go spoza aplikacji, co przydatne jest do instalacji na serwerach. MoÅ¼na go znaleÅºÄ‡ na [https://duplicati-oauth-handler.appspot.com/](https://duplicati-oauth-handler.appspot.com/)

Poza auth_id lub generalnie jakÄ…Å› formÄ… adresu naszego storage backendu warto sparametryzowaÄ‡ Å›cieÅ¼kÄ™, ktÃ³rÄ… backupujemy oraz hasÅ‚o szyfrujÄ…ce pliki i politykÄ™ retencji. 

MajÄ…c na uwadze powyÅ¼sze zapisy moÅ¼na pokusiÄ‡ siÄ™ o napisanie takiego, oto skryptu:

```bash
#!/bin/bash

path=$1
authid=$2
passphrase=$3
retention=$4

path_encoded="`echo ${path} | base32 | tr '=' '_'`"
hostname="`hostname`"

START="$(date +%s)"

EXITCODE=1

for i in `seq 10`
do
	/usr/bin/duplicati-cli backup "dropbox:///PREFIX/${hostname}${path}?authid=${authid}" "${path}" --backup-name="${path}" --dbpath="/var/duplicati_${path_encoded}.sqlite" --encryption-module=aes --compression-module=zip --dblock-size=50mb --passphrase="${passphrase}" --retention-policy="${retention}" --disable-module=console-password-input 
	EXITCODE=$?

	if [ $EXITCODE -lt 10 ]
	then
		break
	fi

	sleep $((1 + RANDOM % 60))
done


END="$(date +%s)"
```


Dzieje siÄ™ w nim kilka nie do koÅ„ca intuicyjnych rzeczy, czas wiÄ™c na wyjaÅ›nienia.

Pierwsza sprawa to docelowa lokalizacja backupÃ³w: umieszczane sÄ… tak jak typowe dane zewnÄ™trznej aplikacji dropboksowej w folderze _Applications_ na Dropboxie w podfolderze _Duplicati backups_ - warto wiÄ™c od razu usunÄ…Ä‡ go z synchronizacji na desktopie - no chyba Å¼e mamy duÅ¼o miejsca na dysku ğŸ™‚ 

Dalsze elementy Å›cieÅ¼ki to prefiks (na screenshocie poniÅ¼ej jest to _amaterasu_ - tak nazywa siÄ™ mÃ³j serwer), nazwa hosta wyciÄ…gana dynamicznie przez skrypt, oraz peÅ‚na Å›cieÅ¼ka do backupowanego foldero - bardzo uÅ‚atwia to lokalizacjÄ™ konkretnych danych.

![](/wp-content/uploads/2020/10/Selection_039.png)

Kolejny element to _dbpath_, ktÃ³ry odpowiada za lokalnÄ… bazÄ™ danych pomagajÄ…cÄ… Duplicati utrzymaÄ‡ stan plikÃ³w. Bashowy potworek `echo ${path} | base32 | tr '=' '_'`, ktÃ³ry tworzy jego wartoÅ›Ä‡ enkoduje Å›cieÅ¼kÄ™ tak by mogÅ‚a byÄ‡ nazwÄ… pliku bazy SQLite. Nie moÅ¼e to byÄ‡ staÅ‚a wartoÅ›Ä‡, gdyÅ¼ wtedy nie moÅ¼na by uruchomiÄ‡ dwÃ³ch rÃ³Å¼nych procesÃ³w backupowania na jednym hoÅ›cie. Natomiast odwracalne base32 z podmianÄ… znaku rÃ³wnoÅ›ci (ktÃ³ry sprawia kÅ‚opot w niektÃ³rych miejscach w bashu) ma tÄ™ przewagÄ™ nad funkcjÄ… skrÃ³tu w rodzaju MD5, Å¼e pÃ³Åºniejsze debugowanie sytuacji w rodzaju przepeÅ‚niajÄ…cej siÄ™ bazy danych jest Å‚atwiejsze.

_Retention policy_ okreÅ›la, ile backupÃ³w z danego okresu ma byÄ‡ przechowywane. Moja domyÅ›lna wartoÅ›Ä‡ to `"1W:1D,4W:1W,12M:1M"`. PoniÅ¼ej wklejam to, co moÅ¼na znaleÅºÄ‡ w helpie duplicati-cli, ale generalnie doÅ›Ä‡ pomocne jest web-ui zawierajÄ…ce kilka czÄ™sto uÅ¼ywanych wartoÅ›ci. 

duplicati-cli help retention-policy:
```
  -retention-policy (String): Reduce number of versions by deleting old intermediate backups

    Use this option to reduce the number of versions that are kept with increasing version age by deleting most of the old backups. The expected format is a comma separated list of colon separated time frame and interval pairs. For example the value "7D:0s,3M:1D,10Y:2M" means "For 7 day keep all backups, for 3 months keep one backup every day, for 10 years one backup every 2nd month and delete every backup older than this.". This option also supports using the specifier "U" to indicate an unlimited time interval.
```

CaÅ‚e wywoÅ‚anie duplicati-cli w moim wrapperze opakowane jest pÄ™tlÄ… prÃ³bujÄ…cÄ… wykonaÄ‡ backup 10 razy, a po kaÅ¼dym niepowodzeniu czekajÄ…c losowÄ… liczbÄ™ sekund od 1 do 60 (linijka ze `sleep`). IstotnÄ… puÅ‚apkÄ… jest tutaj exitcode - duplicati-cli nie do koÅ„ca przestrzega standardu POSIX i nie zawsze kod wyjÅ›cia rÃ³Å¼ny od zera oznacz bÅ‚Ä…d - stÄ…d `[ $EXITCODE -lt 10 ]` w ifie, ktÃ³ry sprawdza, czy moÅ¼na opuÅ›ciÄ‡ pÄ™tlÄ™ for po udanym backupie.

duplicati-cli help returncodes:
```
  Duplicati reports the following return/exit codes:
    0 - Success
    1 - Successful operation, but no files were changed
    2 - Successful operation, but with warnings
    50 - Backup uploaded some files, but did not finish
    100 - An error occurred
    200 - Invalid commandline arguments found
```

## Monitorowanie za pomocÄ… Prometheusa

IdÄ…c za reguÅ‚Ä… Torvaldsa _talk is cheap - show me the code!_ znowu zacznÄ™ od kawaÅ‚ka skryptu, ktÃ³ry potem wyjaÅ›niÄ™ ğŸ™‚

Pierwszym elementem jest lekka modyfikcja wrappera z poprzedniej sekcji tak, by zapisywaÅ‚ metryki.

```bash
# put this before $START variable declaration
metrics_name="duplicati_${hostname}_`echo $path | tr '/' '_'`"
metrics_dir="/var/lib/prometheus/node-exporter/"
mkdir -p $metrics_dir
chown prometheus $metrics_dir

# put this at the end of script - after $END variable
cat << EOF > "$metrics_dir/${metrics_name}.prom.$$"
${metrics_name}_last_run_start $START
${metrics_name}_last_run_seconds $(($END - $START))
${metrics_name}_last_exitcode $EXITCODE
EOF
mv "$metrics_dir/${metrics_name}.prom.$$" "$metrics_dir/${metrics_name}.prom"
```


Dlaczego najpierw zapisujÄ™ tekst do pliku z nazwÄ… koÅ„czÄ…cÄ… siÄ™ na PID procesu (`$$`)? OtÃ³Å¼ jeÅ›li prometheusowy eksporter wstrzeliÅ‚by siÄ™ w moment zapisu do pliku, mÃ³gÅ‚by odczytaÄ‡ uszkodzone metryki. StÄ…d na koniec atomowa operacja _mv_, ktÃ³ra zapewnia integralnoÅ›Ä‡ danych.

PowyÅ¼sze tworzy trzy metryki, ktÃ³re bÄ™dziemy mogli potem odczytaÄ‡ za pomocÄ… pakietu _prometheus_nodexporter_ - uÅ¼ywajÄ… moduÅ‚u _textfile_. SÄ… to: 

  * `duplicati_$hostname_$path_last_run_start` okreÅ›lajÄ…ca ostatni czas startu skryptu
  * `duplicati_$hostname_$path_last_run_seconds` przechowujÄ…ca czas wykonania w sekundach
  * `duplicati_$hostname_$path_last_exitcode` zawierajÄ…ca ostatni kod wyjÅ›cia skryptu

Kombinacja `last_run_start` oraz `last_exitcode` pozwoli kwerendzie Prometheusa ustaliÄ‡, czy host sprÃ³bowaÅ‚ zaczÄ…Ä‡ backup w ustalonym okresie (np. 24h) oraz co mu z tego wyszÅ‚o. `last_run_secods` moÅ¼e siÄ™ przydaÄ‡ do pÃ³Åºniejszej analizy statystyk czy coÅ› nie wykonywaÅ‚o siÄ™ za dÅ‚ugo. 

Sam Prometheus to ogromny temat, dlatego poruszÄ™ tu tylko dwa elementy w jednym z wielu moÅ¼liwych setupÃ³w - node_exporter na monitorowanym boksie i sam prometheus na centralnym serwerze monitorujÄ…cym. Ten drugi moÅ¼na poszerzyÄ‡ o alertmanagera i integracjÄ™ na przykÅ‚ad z PagerDuty.

Zacznijmy zatem od centralnego prometheusa. Potrzeba nam przynajmniej trzech plikÃ³w konfiguracyjnych: `/etc/default/prometheus` zawierajÄ…cego ogÃ³lne parametry takie jak IP serwera, `/etc/prometheus/prometheus.yml` definiujÄ…cego interwaÅ‚y checkÃ³w oraz ÅºrÃ³dÅ‚a danych, czyli monitorowane hosty oraz przynajmniej jednego pliku z reguÅ‚ami alertÃ³w znajdujÄ…cego siÄ™ w `/etc/prometheus/rules/`.

Minimalna zawartoÅ›Ä‡ `/etc/default/prometheus` to `ARGS="--web.listen-address=EXTERNAL_IP:9090"`. Zadeklarowanie adresu IP explicite jest waÅ¼ne jeÅ›li przypadkiem mamy wÅ‚Ä…czonÄ… obsÅ‚ugÄ™ IPv6 - golangowe biblioteki uÅ¼ywane przez prometheusa upierajÄ… siÄ™ na bindowanie do IPv6 przed IPv4, a sam prometheus binduje siÄ™ tylko do pierwszego adresu. 

Kolej na `prometheus.yml`. Potrzebujemy czegoÅ› w rodzaju:

```yaml
global:
  evaluation_interval: 15s
  scrape_interval: 15s
  scrape_timeout: 10s

  external_labels:
    environment: prometheus

rule_files:
  - /etc/prometheus/rules/*.rules

scrape_configs:
  - job_name: 'MONITORED_HOST'
    static_configs:
    - targets: ['MONITORED_HOST_IP:9100']
  - job_name: 'MONITORED_HOST2'
    static_configs:
    - targets: ['MONITORED_HOST2_IP:9100']
...
```


I na koniec plik z reguÅ‚kami. PozwolÄ™ sobie, zamiast konkretnej wartoÅ›ci, wskazaÄ‡ Jinjowy template, ktÃ³rego uÅ¼ywam w Ansiblu by go wygerowaÄ‡:

```yaml
---
groups:
- name: Amaterasu
  rules:
{% for dj in duplicati_monitored_jobs %}
  - alert: MONITORED DUPLICATI JOB {{dj.metric}} DIDNT START IN 24hrs
    annotations:
      message: '{{dj.metric}}'
      description: 'todo: add last exec time here'
    expr:
      time()-duplicati_{{dj.metric}}_last_run_start>86400
      or
      absent(duplicati_{{dj.metric}}_last_run_start)
    for: 1m
    labels:
      severity: error

  - alert: MONITORED DUPLICATI JOB {{dj.metric}} HAD FAILURE
    annotations:
      message: '{{dj.metric}}'
      description: 
    expr:
      duplicati_{{dj.metric}}_last_exitcode>9
    for: 1m
    labels:
      severity: error
{% endfor %}
```


Praktyczny foreach stworzy automatycznie dwa alerty na kaÅ¼dy monitorowany job duplicati - jeden sprawdzajÄ…cy, czy backup siÄ™ uruchomiÅ‚ w ciÄ…gu ostatniej doby, a drugi czy exitcode oznacza sukces kopii zapasowej. Warto zwrÃ³ciÄ‡ uwagÄ™ na `or absent(...)` - pozwala to zÅ‚apaÄ‡ takÅ¼e przypadki kiedy metryka w ogÃ³le wyparowaÅ‚a z systemu - PromQL (czyli SQL uÅ¼ywany przez Prometheusa) nie uznaje `null` jako wektora danych.

Natomiast przechowywana w ansiblowym `host_vars` tablica `duplicati_monitored_jobs` wyglÄ…daÄ‡ moÅ¼e tak jak w poniÅ¼szym wycinku. Godne uwagi jest to, Å¼e wartoÅ›ci pola `metric` sÄ… zgodne z wartoÅ›ciÄ… `$metrics_name` stworzonÄ… we wrapperze.

```yaml
---
duplicati_monitored_jobs:
  - metric: influx01__var_lib_influxdb
  - metric: psql01__var_lib_postgresql
  - metric: mysql01__var_lib_mysql
```


Teraz warto zainstalowaÄ‡ i skonfigurowaÄ‡ _prometheus_nodexporter_ na monitorowanych boksach. Paczka na wiÄ™kszoÅ›ci systemÃ³w nazywa siÄ™ tak jak binarka. Konfiguracja odbywa siÄ™ poprzez plik `/etc/default/prometheus`. Na pewno musimy w nim zawrzeÄ‡ przynajmniej `ARGS="--web.listen-address=EXTERNAL_IP:9090 --collector.textfile.directory=/var/lib/prometheus/node-exporter"`. IP jest tu z tego samego powodu co w serwerze, zaÅ› `--collector.textfile.directory` znany jest nam juÅ¼ jako `$metrics_dir` z wrappera.

Efekt naszych staraÅ„ powinien przypominaÄ‡ coÅ› takiego w Prometheusowym WebUI:


![](/wp-content/uploads/2020/10/Selection_040.png)

## Deployment jobÃ³w

Ostatnim krokiem jest zdeployowanie naszych jobÃ³w, czyli zasadniczo wpisÃ³w w crontab z wywoÅ‚aniem skryptu wrappera. PoniÅ¼ej ansiblowy playbook, ktÃ³ry dodatkowo zajmie siÄ™ zainstalowaniem dependencji.

```yaml
---
- name: 'install duplicati'
  apt:
    deb: 'https://updates.duplicati.com/beta/duplicati_{{duplicati_ver}}_all.deb'
- name: 'install wrapper'
  copy:
    src: 'duplicati_wrapper.sh'
    dest: '/opt/duplicati_wrapper.sh'
    mode: 555

- name: 'set up schedules'
  cron:
    name: 'duplicati_{{item.path}}'
    minute: '{{item.minute}}'
    hour: '{{item.hour}}'
    job: /opt/duplicati_wrapper.sh {{item.path}} {{duplicati_dropbox_authid}} {{duplicati_passphrase}} '{{item.retention}}'
  with_items: '{{duplicati_jobs}}'

- name: 'make sure prometheus_nodexporter is set up - param'
  lineinfile:
    line: 'ARGS="$ARGS --collector.textfile.directory=/var/lib/prometheus/node-exporter"'
    path: '/etc/default/prometheus'
- name: 'make sure prometheus_nodexporter is set up - dir'
  file: 
    path: '/var/lib/prometheus/node-exporter'
    state: directory
    owner: prometheus
- name: 'make sure prometheus_nodexporter is set up - service'
  systemd:
    name: 'prometheus-node-exporter'
    state: restarted
```


Å»eby ten playbook dziaÅ‚aÅ‚ potrzeba nam `duplicati_wrapper.sh` czyli skryptu wrappera, ktÃ³ry napisaliÅ›my w dwÃ³ch poprzednich sekcjach oraz kilku zmiennych:

  * `duplicati_ver` - obecnie najnowsza to `2.0.5.1-1`
  * `duplicati_dropbox_authid` - coÅ›, co uzyskamy z <https://duplicati-oauth-handler.appspot.com/>
  * `duplicati_passphrase` - hasÅ‚o do szyfrowania AES256 - najlepiej, jeÅ›li bÄ™dzie ustawione na poziomie hosta
  * `duplicati_jobs` - tablica z opisem jobÃ³w - musi byÄ‡ ustawiona per host, przykÅ‚ad poniÅ¼ej

```yaml
---
duplicati_jobs:
  - path: /var/lib/influxdb/
    retention: "1W:1D,4W:1W,12M:1M"
    hour: 2
    minute: 0
```


CaÅ‚oÅ›Ä‡ najlepiej upakowaÄ‡ do ansiblowej roli, ktÃ³rÄ… moÅ¼na dodaÄ‡ do playbooka tworzÄ…cego maszyny lub osobnego deployujÄ…cego nowe konfiguracje do wszystkich monitorowanych hostÃ³w.

## Podsumowanie

Duplicati jest bardzo przyjemnym w uÅ¼ywaniu systemem backupÃ³w, a wÅ‚aÅ›ciwie to nie systemem, a zestawem narzÄ™dzi, ktÃ³re backupy tworzÄ… po stronie klienta. Daje to wygodÄ™ w doborze metody automatyzacji - w tym uÅ¼ywaniu wbudowanego w narzÄ™dzie dla desktopÃ³w schedulera oraz miejsca docelowego z naciskiem na mnogoÅ›Ä‡ form backupu do chmury. 

W artykule opisaÅ‚em jak w szybki sposÃ³b zintegrowaÄ‡ Duplicati na serwerach przy uÅ¼yciu crontaba i prostego wrappera oraz monitorowaÄ‡ stan uÅ¼ywajÄ… Prometheusa.

 [1]: /2017/07/prosty-choc-nie-zawsze-trywialny-w-obsludze-system-backupowania-urbackup/
 [2]: /wp-content/uploads/2020/10/Selection_039.png
 [3]: /wp-content/uploads/2020/10/Selection_040.png